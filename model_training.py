# model_training.py
import pandas as pd
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import train_test_split

# Step 1: Load dataset
data = pd.read_csv('fer2013.csv')

# Inspect for missing values in the 'pixels' column
print("Missing values in 'pixels' column:", data['pixels'].isnull().sum())

# Step 2: Prepare data
def preprocess_data(data):
    X = []
    y = []
    # Filter out rows with missing 'pixels' values before processing
    data = data.dropna(subset=['pixels'])
    for i in range(len(data)):
        pixels = np.array(data['pixels'].iloc[i].split(), dtype='float32')
        X.append(pixels)
        y.append(data['emotion'].iloc[i])
    X = np.array(X)
    y = np.array(y)
    X = X.reshape(-1, 48, 48, 1) / 255.0
    y = to_categorical(y, num_classes=7)
    return X, y

# Preprocess the entire dataset
X, y = preprocess_data(data)

# Split data into training, validation, and test sets
X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)


# Step 3: Build the CNN model
model = Sequential([
    Conv2D(32, (3,3), activation='relu', input_shape=(48,48,1)),
    MaxPooling2D(2,2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(7, activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Step 4: Train the model
model.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_val, y_val))

# Step 5: Evaluate on test data
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f'Test accuracy: {test_acc * 100:.2f}%')

# Step 6: Save the model
model.save('face_emotionModel.h5')
